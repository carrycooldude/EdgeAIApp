# Project Structure Documentation

## ğŸ“ **EdgeAI Project Organization**

This document describes the improved project structure for EdgeAI v1.3.0 with real ExecuTorch + QNN integration.

## ğŸ—ï¸ **Directory Structure**

```
EdgeAI/
â”œâ”€â”€ ğŸ“± app/                                    # Android application
â”‚   â”œâ”€â”€ src/main/
â”‚   â”‚   â”œâ”€â”€ ğŸ“± cpp/                           # Native C++ implementation
â”‚   â”‚   â”‚   â”œâ”€â”€ real_executorch_qnn.cpp      # ğŸ¯ Main ExecuTorch + QNN integration
â”‚   â”‚   â”‚   â”œâ”€â”€ CMakeLists.txt               # Build configuration
â”‚   â”‚   â”‚   â”œâ”€â”€ qnn_infer.cpp                # QNN inference utilities
â”‚   â”‚   â”‚   â”œâ”€â”€ qnn_manager.cpp              # QNN manager implementation
â”‚   â”‚   â”‚   â””â”€â”€ ...                          # Other C++ files
â”‚   â”‚   â”œâ”€â”€ â˜• java/                          # Kotlin/Java code
â”‚   â”‚   â”‚   â””â”€â”€ com/example/edgeai/
â”‚   â”‚   â”‚       â”œâ”€â”€ ml/                      # Machine learning classes
â”‚   â”‚   â”‚       â”‚   â””â”€â”€ LLaMAInference.kt   # ğŸ¯ Main inference class
â”‚   â”‚   â”‚       â”œâ”€â”€ ui/                      # User interface
â”‚   â”‚   â”‚       â””â”€â”€ ...                      # Other classes
â”‚   â”‚   â”œâ”€â”€ ğŸ“¦ assets/                       # Model files and resources
â”‚   â”‚   â”‚   â”œâ”€â”€ models/                      # Model files
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ Llama3.2-1B/            # Llama3.2-1B model
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ...                      # Other models
â”‚   â”‚   â”‚   â”œâ”€â”€ context_binaries/            # QNN context binaries
â”‚   â”‚   â”‚   â””â”€â”€ tokenizer/                   # Tokenizer files
â”‚   â”‚   â””â”€â”€ ğŸ“± res/                          # Android resources
â”‚   â””â”€â”€ build.gradle.kts                     # App build configuration
â”œâ”€â”€ ğŸ“š docs/                                  # Documentation
â”‚   â”œâ”€â”€ technical/                           # Technical documentation
â”‚   â”‚   â”œâ”€â”€ REAL_EXECUTORCH_QNN_INTEGRATION.md  # ğŸ¯ Integration guide
â”‚   â”‚   â”œâ”€â”€ IMPLEMENTATION_ANALYSIS.md         # Implementation analysis
â”‚   â”‚   â””â”€â”€ ARCHITECTURE.md                    # Architecture overview
â”‚   â”œâ”€â”€ setup/                               # Setup guides
â”‚   â”‚   â”œâ”€â”€ QUALCOMM_AIHUB_SETUP.md          # Qualcomm AI HUB setup
â”‚   â”‚   â”œâ”€â”€ EXECUTORCH_SETUP.md              # ExecuTorch setup
â”‚   â”‚   â””â”€â”€ ANDROID_SETUP.md                 # Android setup
â”‚   â””â”€â”€ releases/                            # Release notes
â”‚       â”œâ”€â”€ RELEASE_NOTES_v1.3.0.md          # Latest release
â”‚       â”œâ”€â”€ RELEASE_NOTES_v1.2.0.md          # Previous releases
â”‚       â””â”€â”€ ...
â”œâ”€â”€ ğŸ”§ scripts/                              # Build and setup scripts
â”‚   â”œâ”€â”€ setup_real_executorch.ps1            # ğŸ¯ Main setup script
â”‚   â”œâ”€â”€ copy_model_to_device.ps1             # Model deployment
â”‚   â””â”€â”€ ...                                  # Other scripts
â”œâ”€â”€ ğŸ“¦ external_models/                      # External model files
â”‚   â””â”€â”€ Llama-3-8b-chat-hf/                 # Large model files
â”œâ”€â”€ ğŸ—ï¸ build.gradle.kts                      # Project build configuration
â”œâ”€â”€ ğŸ“‹ settings.gradle.kts                   # Project settings
â”œâ”€â”€ ğŸ“„ README.md                             # ğŸ¯ Main project documentation
â”œâ”€â”€ ğŸ“„ LICENSE                                # License file
â””â”€â”€ ğŸ“„ CONTRIBUTING.md                       # Contributing guidelines
```

## ğŸ¯ **Key Files and Their Purpose**

### **Core Implementation Files**

| File | Purpose | Importance |
|------|---------|------------|
| `app/src/main/cpp/real_executorch_qnn.cpp` | **Main ExecuTorch + QNN integration** | ğŸ¯ **Critical** |
| `app/src/main/java/com/example/edgeai/ml/LLaMAInference.kt` | **Main inference class** | ğŸ¯ **Critical** |
| `app/src/main/cpp/CMakeLists.txt` | **Native build configuration** | ğŸ”§ **Important** |
| `app/build.gradle.kts` | **Android build configuration** | ğŸ”§ **Important** |

### **Documentation Files**

| File | Purpose | Importance |
|------|---------|------------|
| `README.md` | **Main project documentation** | ğŸ¯ **Critical** |
| `docs/technical/REAL_EXECUTORCH_QNN_INTEGRATION.md` | **Integration guide** | ğŸ¯ **Critical** |
| `docs/technical/IMPLEMENTATION_ANALYSIS.md` | **Implementation analysis** | ğŸ“– **Important** |
| `docs/setup/QUALCOMM_AIHUB_SETUP.md` | **Setup guide** | ğŸ“– **Important** |

### **Script Files**

| File | Purpose | Importance |
|------|---------|------------|
| `scripts/setup_real_executorch.ps1` | **Main setup script** | ğŸ”§ **Important** |
| `scripts/copy_model_to_device.ps1` | **Model deployment** | ğŸ”§ **Important** |

## ğŸ”§ **Build System**

### **Android Build (Gradle)**

```kotlin
// app/build.gradle.kts
android {
    defaultConfig {
        ndk {
            abiFilters += listOf("arm64-v8a") // For v79 context binaries
        }
    }
    
    externalNativeBuild {
        cmake {
            path = file("src/main/cpp/CMakeLists.txt")
            version = "3.22.1"
        }
    }
}
```

### **Native Build (CMake)**

```cmake
# app/src/main/cpp/CMakeLists.txt
cmake_minimum_required(VERSION 3.22.1)
project("edgeai_qnn")

# ExecuTorch flags for v79
set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -DEXECUTORCH_ENABLE_QNN=1")
set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -DEXECUTORCH_CONTEXT_BINARIES_V79=1")

# Define native library
add_library(edgeai_qnn SHARED
    real_executorch_qnn.cpp  # Main implementation
    qnn_infer.cpp
    qnn_manager.cpp
)
```

## ğŸ“± **Android Architecture**

### **UI Layer**
- **MainActivity.kt**: Main activity with UI
- **LLaMAInference.kt**: Core inference logic
- **JNI Bridge**: Communication between Kotlin and C++

### **Native Layer**
- **real_executorch_qnn.cpp**: ExecuTorch + QNN integration
- **qnn_infer.cpp**: QNN inference utilities
- **qnn_manager.cpp**: QNN manager implementation

### **Asset Layer**
- **models/**: Model files (.pte, .pth)
- **context_binaries/**: QNN context binaries
- **tokenizer/**: Tokenizer files

## ğŸš€ **Development Workflow**

### **1. Setup**
```bash
# Run setup script
.\scripts\setup_real_executorch.ps1
```

### **2. Development**
```bash
# Build debug version
.\gradlew assembleDebug

# Install on device
adb install app\build\outputs\apk\debug\app-debug.apk
```

### **3. Testing**
```bash
# Run tests
.\gradlew test

# Run Android tests
.\gradlew connectedAndroidTest
```

### **4. Release**
```bash
# Build release version
.\gradlew assembleRelease

# Generate release APK
.\gradlew bundleRelease
```

## ğŸ“Š **File Size Analysis**

### **Large Files**
- `external_models/Llama-3-8b-chat-hf/consolidated.00.pth`: ~2.3GB
- `app/build/outputs/apk/debug/app-debug.apk`: ~50MB
- `app/build/outputs/apk/release/app-release.apk`: ~30MB

### **Documentation**
- `README.md`: ~15KB
- `docs/technical/REAL_EXECUTORCH_QNN_INTEGRATION.md`: ~25KB
- `docs/technical/IMPLEMENTATION_ANALYSIS.md`: ~10KB

## ğŸ” **Code Organization**

### **C++ Code Structure**
```cpp
// real_executorch_qnn.cpp
class RealExecuTorchQNNInference {
private:
    // Model configuration
    // ExecuTorch components
    // QNN backend components
    // Tokenizer components
    
public:
    // Initialization
    // Inference methods
    // Utility methods
};
```

### **Kotlin Code Structure**
```kotlin
// LLaMAInference.kt
class LLaMAInference {
    companion object {
        // Native method declarations
        // Constants
    }
    
    // Initialization methods
    // Inference methods
    // Utility methods
}
```

## ğŸ¯ **Best Practices**

### **File Naming**
- Use descriptive names: `real_executorch_qnn.cpp`
- Include version info: `RELEASE_NOTES_v1.3.0.md`
- Use consistent casing: `LLaMAInference.kt`

### **Documentation**
- Keep README.md up to date
- Document all public APIs
- Include code examples
- Use clear, concise language

### **Code Organization**
- Separate concerns into different files
- Use meaningful class and method names
- Add comments for complex logic
- Follow consistent formatting

## ğŸ”§ **Maintenance**

### **Regular Tasks**
- Update documentation with new features
- Clean up unused files
- Optimize build configuration
- Update dependencies

### **Version Management**
- Update version numbers in build files
- Create release notes for each version
- Tag releases in Git
- Update documentation

This improved structure makes the project more maintainable, easier to understand, and better organized for future development.
